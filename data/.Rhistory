BIC(model.saturated,
model.reduced1,
model.reduced2)
print('based on the AIC, BIC, R^2 and RSE values, using the most reduced model does not significantly reduce accuracy, and therefore model.reduced1 is the least complex providing the lowest BIC and nearly the same accuracy.')
print('Food and Decor appear to have the most predictive value in restaurant price.  Service and location are correlated with price but are providing redundant information as they are multicollinear with existing features. A reduced model using food and decor scores provide the most accurate model with the least complexity and redundancy.')
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
prostate = read.table("https://s3.amazonaws.com/nycdsabt01/Prostate.txt", header = TRUE)
View(prostate)
##########################
library(ISLR)
install.packages("ISLR")
install.packages("ISLR")
##########################
library(ISLR)
#Create Matrix
x = model.matrix(lpsa ~ ., prostate)[, -1] #Dropping the intercept column.
y = prostate$lpsa
#Creating training and testing sets. Here we decide to use a 78-20 split with
#approximately 80% of our data in the training set and 20% of our data in the
#test set.
set.seed(0)
train = sample(1:nrow(x), 8*nrow(x)/10)
test = (-train)
y.test = y[test]
length(train)/nrow(x)
length(y.test)/nrow(x)
install.packages("glmnet")
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(ridge.models) #Inspecting the various coefficient estimates.
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.models)) #9 different coefficients, estimated 100 times --
#once each per lambda value.
coeficients = coef(ridge.models) #Inspecting the various coefficient estimates.
#Visualizing the ridge regression shrinkage.
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
bestlambda.ridge
log(bestlambda.ridge)
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
bestlambda.ridge
log(bestlambda.ridge)
bestlambda.ridge = cv.ridge.out$lambda.min
log(bestlambda.ridge)
#What is the test MSE associated with this best value of lambda?
ridge.bestlambdatrain = predict(ridge.models.train, s = bestlambda.ridge, newx = x[test, ])
#What is the test MSE associated with this best value of lambda?
ridge.bestlambdatrain = predict.cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[test, ])
mean((ridge.bestlambdatrain - y.test)^2)
#What is the test MSE associated with this best value of lambda?
ridge.bestlambdatrain = predict.cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[train, ])
mean((ridge.bestlambdatrain - y[train])^2)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(dplyr)
df1 = case2002%>%
select(., LC, AG, YR, CD)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(dplyr)
df1 = case2002%>%
select(., LC, AG, YR, CD)
setwd("~/NYCDSA/Data")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(Sleuth2)
data(case2002)
?case2002
library(dplyr)
df1 = case2002%>%
select(., LC, AG, YR, CD)
plot(df1, col = as.factor(df1$LC))
print('Years of Smoking and Age of Subject violate multicollinearity assumption.')
library(car)
summary(logit.overall)
library(dplyr)
df2 = case2002
logit.overall = glm(LC ~ AG + YR + CD + FM + SS + BK, data = df2, family = "binomial")
#df2$LC = as.factor(df2$LC)
#df2$FM = as.factor(df2$FM)
#df2$SS = as.factor(df2$SS)
#df2$BK = as.factor(df2$BK)
library(car)
summary(logit.overall)
scatter.smooth(logit.overall$fit,
residuals(logit.overall, type = "deviance"),
lpars = list(col = "red"),
xlab = "Fitted Probabilities",
ylab = "Deviance Residual Values",
main = "Residual Plot for\nLogistic Regression of Birdkeeping and Lung Cancer")
abline(h = 0, lty = 2)
summary(logit.overall)
influencePlot(logit.overall)
print('Only Bird Keeping and years of smoking features have statistical significance')
library(dplyr)
df2 = case2002
logit.no_bk = glm(LC ~ AG + YR + CD + FM + SS, data = df2, family = "binomial")
summary(logit.no_bk)
print('The AIC has increased from 168.2 to 177.87')
library(dplyr)
df3 = case2002
logit.bk_yr = glm(LC ~ YR + BK, data = df3, family = "binomial")
summary(logit.bk_yr)
#A
newdata1 = with(case2002, data.frame(YR = mean(YR),BK = 'NoBird'))
#predict(logit.bk_yr, newdata1)
exp(predict(logit.bk_yr, newdata1))/(1 + exp(predict(logit.bk_yr, newdata1)))
#B
newdata2 = with(case2002, data.frame(YR = 0,BK = 'NoBird'))
#predict(logit.bk_yr, newdata2)
exp(predict(logit.bk_yr, newdata2))/(1 + exp(predict(logit.bk_yr, newdata2)))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
prostate = read.table("https://s3.amazonaws.com/nycdsabt01/Prostate.txt", header = TRUE)
##########################
library(ISLR)
#Create Matrix
x = model.matrix(lpsa ~ ., prostate)[, -1] #Dropping the intercept column.
y = prostate$lpsa
#Creating training and testing sets. Here we decide to use a 80-20 split with
#approximately 80% of our data in the training set and 20% of our data in the
#test set.
set.seed(0)
train = sample(1:nrow(x), 8*nrow(x)/10)
test = (-train)
y.test = y[test]
#confirm size
length(train)/nrow(x)
length(y.test)/nrow(x)
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
coeficients = coef(ridge.models) #Inspecting the various coefficient estimates.
dim(coef(ridge.models)) #9 different coefficients, estimated 100 times --
#once each per lambda value.
#Visualizing the ridge regression shrinkage.
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")
View(prostate)
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
log(bestlambda.ridge)
cv.ridge.out$lambda.min
bestlambda.ridge = cv.ridge.out$lambda.min
log(bestlambda.ridge)
cv.ridge.out
ridge.bestlambdatrain = predict.cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[test, ])
mean((ridge.bestlambdatrain - y.test)^2)
ridge.bestlambdatrain = predict.cv.glmnet(cv.ridge.out, s ="lambda.min", newx = x[train, ])
mean((ridge.bestlambdatrain - y[train])^2)
#The MSE is smaller because we have accounted for the variability in the training set.
setwd("~/NYCDSA/Projects/ML_Project/data")
#####################################################
############ Multi Linear Regression ################
#####################################################
train = read.csv('train_clean_std_full.csv')
library(corrplot)
library(dplyr)
#Basic numerical EDA for states dataset.
#summary(train)
#sapply(train, sd)
#corr = cor(train)
#Basic graphical EDA for the train dataset.
#plot(train)
#corrplot(corr, method="circle")
#Creating a saturated model (a model with all variables included).
model.saturated = lm(SalePrice ~ ., data = train)
#summary(model.saturated) #Many predictor variables are not significant, yet the
#overall regression is significant.
plot(model.saturated) #Assessing the assumptions of the model.
#####################################################
############ Multi Linear Regression ################
#####################################################
train = read.csv('train_clean_std_full.csv')
library(corrplot)
library(dplyr)
#Basic numerical EDA for states dataset.
#summary(train)
#sapply(train, sd)
#corr = cor(train)
#Basic graphical EDA for the train dataset.
#plot(train)
#corrplot(corr, method="circle")
#Creating a saturated model (a model with all variables included).
model.saturated = lm(SalePrice ~ ., data = train)
#summary(model.saturated) #Many predictor variables are not significant, yet the
#overall regression is significant.
plot(model.saturated) #Assessing the assumptions of the model.
setwd("~/NYCDSA/Projects/ML_Project/JF/data")
#####################################################
############ Multi Linear Regression ################
#####################################################
train = read.csv('train_clean_std_full.csv')
library(corrplot)
library(dplyr)
#Basic numerical EDA for states dataset.
#summary(train)
#sapply(train, sd)
#corr = cor(train)
#Basic graphical EDA for the train dataset.
#plot(train)
#corrplot(corr, method="circle")
#Creating a saturated model (a model with all variables included).
model.saturated = lm(SalePrice ~ ., data = train)
#summary(model.saturated) #Many predictor variables are not significant, yet the
#overall regression is significant.
plot(model.saturated) #Assessing the assumptions of the model.
setwd("~/NYCDSA/Projects/ML_Project/data")
#####################################################
############ Multi Linear Regression ################
#####################################################
train = read.csv('train_clean_std_full.csv')
library(corrplot)
library(dplyr)
#Basic numerical EDA for states dataset.
#summary(train)
#sapply(train, sd)
#corr = cor(train)
#Basic graphical EDA for the train dataset.
#plot(train)
#corrplot(corr, method="circle")
#Creating a saturated model (a model with all variables included).
model.saturated = lm(SalePrice ~ ., data = train)
#summary(model.saturated) #Many predictor variables are not significant, yet the
#overall regression is significant.
plot(model.saturated) #Assessing the assumptions of the model.
#######################################################
#######################################################
###### [06] Regularization and Cross validation #######
#######################################################
#######################################################
##########################
#####Ridge Regression#####
##########################
library(ISLR)
Hitters = na.omit(Hitters)
help(Hitters)
#Need matrices for glmnet() function. Automatically conducts conversions as well
#for factor variables into dummy variables.
x = model.matrix(Salary ~ ., Hitters)[, -1] #Dropping the intercept column.
y = Hitters$Salary
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Fitting the ridge regression. Alpha = 0 for ridge regression.
library(glmnet)
ridge.models = glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(ridge.models) #Inspecting the various coefficient estimates.
#What do the estimates look like for a smaller value of lambda?
ridge.models$lambda[80] #Lambda = 0.2595.
coef(ridge.models)[, 80] #Estimates not close to 0.
sqrt(sum(coef(ridge.models)[-1, 80]^2)) #L2 norm is 136.8179.
ridge.models$lambda[15] #Lambda = 10,235.31.
coef(ridge.models)[, 15] #Most estimates close to 0.
sqrt(sum(coef(ridge.models)[-1, 15]^2)) #L2 norm is 7.07.
#Visualizing the ridge regression shrinkage.
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")
#Can use the predict() function to obtain ridge regression coefficients for a
#new value of lambda, not necessarily one that was within our grid:
predict(ridge.models, s = 50, type = "coefficients")
set.seed(0)
train = sample(1:nrow(x), 7*nrow(x)/10)
test = (-train)
y.test = y[test]
length(train)/nrow(x)
length(y.test)/nrow(x)
#We will arbitrarily choose 5. We will now use the training set exclusively.
ridge.models.train = glmnet(x[train, ], y[train], alpha = 0, lambda = grid)
ridge.lambda5 = predict(ridge.models.train, s = 5, newx = x[test, ])
mean((ridge.lambda5 - y.test)^2)
#What would happen if we fit a ridge regression with an extremely large value
#of lambda? Essentially, fitting a model with only an intercept:
ridge.largelambda = predict(ridge.models.train, s = 1e10, newx = x[test, ])
mean((ridge.largelambda - y.test)^2)
#Running 10-fold cross validation.
set.seed(0)
cv.ridge.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
bestlambda.ridge
log(bestlambda.ridge)
### Alternative method with caret
library(caret)
set.seed(0)
train_control = trainControl(method = 'cv', number=10)
tune.grid = expand.grid(lambda = grid, alpha=c(0))
ridge.caret = train(x[train, ], y[train],
method = 'glmnet',
trControl = train_control, tuneGrid = tune.grid)
### Plot the tuning object:
plot(ridge.caret, xTrans=log)
### Plot the tuning object:
plot(ridge.caret, xTrans=log)
library(glmnet)
library(caret)
train = read.csv('train_clean_std_full.csv')
##########################
#####Lasso Regression#####
##########################
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
library(glmnet)
library(caret)
train = read.csv('train_clean_std_full.csv')
##########################
#####Lasso Regression#####
##########################
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
library(glmnet)
library(caret)
train = read.csv('train_clean_std_full.csv')
x = model.matrix(SalePrice ~ ., train)[, -1] #Dropping the intercept column.
y = train$SalePrice
##########################
#####Lasso Regression#####
##########################
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
library(glmnet)
library(caret)
train = read.csv('train_clean_std_full.csv')
x = model.matrix(SalePrice ~ ., train)[, -1] #Dropping the intercept column.
y = train$SalePrice
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
##########################
#####Lasso Regression#####
##########################
#Fitting the lasso regression. Alpha = 1 for lasso regression.
lasso.models = glmnet(x, y, alpha = 1, lambda = grid)
dim(coef(lasso.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(lasso.models) #Inspecting the various coefficient estimates.
#What do the estimates look like for a smaller value of lambda?
lasso.models$lambda[80] #Lambda = 0.2595.
coef(lasso.models)[, 80] #Most estimates not close to 0.
sum(abs(coef(lasso.models)[-1, 80])) #L1 norm is 228.1008.
#What do the estimates look like for a larger value of lambda?
lasso.models$lambda[15] #Lambda = 10,235.31.
coef(lasso.models)[, 15] #Estimates all 0.
sum(abs(coef(lasso.models)[-1, 15])) #L1 norm is essentially 0.
#Visualizing the lasso regression shrinkage.
plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Can use the predict() function to obtain lasso regression coefficients for a
#new value of lambda, not necessarily one that was within our grid:
predict(lasso.models, s = 50, type = "coefficients")
#Let's attempt to fit a lasso regression using some arbitrary value of lambda;
#we still have not yet figured out what the best value of lambda should be!
#We will arbitrarily choose 5. We will now use the training set exclusively.
lasso.models.train = glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
lasso.lambda5 = predict(lasso.models.train, s = 5, newx = x[test, ])
mean((lasso.lambda5 - y.test)^2)
#Here, the MSE is approximately 107,660.
#Instead of arbitrarily choosing random lambda values and calculating the MSE
#manually, it's a better idea to perform cross-validation in order to choose
#the best lambda over a slew of values.
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
#What is the test MSE associated with this best value of lambda?
lasso.bestlambdatrain = predict(lasso.models.train, s = bestlambda.lasso, newx = x[test, ])
mean((lasso.bestlambdatrain - y.test)^2)
#This time the MSE is actually higher at approximately 113,636. What happened?
### Exercise: Tune the same lasso model with caret!
##########################
#####Lasso Regression#####
##########################
#Values of lambda over which to check.
grid = 10^seq(5, -2, length = 100)
##########################
#####Lasso Regression#####
##########################
#Fitting the lasso regression. Alpha = 1 for lasso regression.
lasso.models = glmnet(x, y, alpha = 1, lambda = grid)
dim(coef(lasso.models)) #20 different coefficients, estimated 100 times --
#once each per lambda value.
coef(lasso.models) #Inspecting the various coefficient estimates.
#What do the estimates look like for a smaller value of lambda?
lasso.models$lambda[80] #Lambda = 0.2595.
coef(lasso.models)[, 80] #Most estimates not close to 0.
sum(abs(coef(lasso.models)[-1, 80])) #L1 norm is 228.1008.
#What do the estimates look like for a larger value of lambda?
lasso.models$lambda[15] #Lambda = 10,235.31.
coef(lasso.models)[, 15] #Estimates all 0.
sum(abs(coef(lasso.models)[-1, 15])) #L1 norm is essentially 0.
#Visualizing the lasso regression shrinkage.
plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Can use the predict() function to obtain lasso regression coefficients for a
#new value of lambda, not necessarily one that was within our grid:
predict(lasso.models, s = 50, type = "coefficients")
#Let's attempt to fit a lasso regression using some arbitrary value of lambda;
#we still have not yet figured out what the best value of lambda should be!
#We will arbitrarily choose 5. We will now use the training set exclusively.
lasso.models.train = glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
lasso.lambda5 = predict(lasso.models.train, s = 5, newx = x[test, ])
mean((lasso.lambda5 - y.test)^2)
#Here, the MSE is approximately 107,660.
#Instead of arbitrarily choosing random lambda values and calculating the MSE
#manually, it's a better idea to perform cross-validation in order to choose
#the best lambda over a slew of values.
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x[train, ], y[train],
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
#What is the test MSE associated with this best value of lambda?
lasso.bestlambdatrain = predict(lasso.models.train, s = bestlambda.lasso, newx = x[test, ])
mean((lasso.bestlambdatrain - y.test)^2)
lasso.models = glmnet(x, y, alpha = 1, lambda = grid)
dim(coef(lasso.models)) #20 different coefficients, estimated 100 times --
coef(lasso.models) #I
lasso.models$lambda[80] #Lambda = 0.2595.
coef(lasso.models)[, 80] #Most estimates not close to 0.
sum(abs(coef(lasso.models)[-1, 80])) #L1 norm is 228.1008.
#What do the estimates look like for a larger value of lambda?
lasso.models$lambda[15] #Lambda = 10,235.31.
coef(lasso.models)[, 15] #Estimates all 0.
sum(abs(coef(lasso.models)[-1, 15])) #L1 norm is essentially 0.
plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")
plot(lasso.models, xvar = "lambda", label = TRUE, main = "Lasso Regression")
predict(lasso.models, s = 50, type = "coefficients")
lasso.models.train = glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
lasso.models.train = glmnet(x, y, alpha = 1, lambda = grid)
lasso.lambda5 = predict(lasso.models.train, s = 5, newx = x[test, ])
lasso.lambda5 = predict(lasso.models.train, s = 5, newx = x)
mean((lasso.lambda5 - y.test)^2)
#Running 10-fold cross validation.
set.seed(0)
cv.lasso.out = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso.out, main = "Lasso Regression\n")
bestlambda.lasso = cv.lasso.out$lambda.min
bestlambda.lasso
log(bestlambda.lasso)
### Alternative method with caret
library(caret)
set.seed(0)
train_control = trainControl(method = 'cv', number=10)
tune.grid = expand.grid(lambda = grid, alpha=c(0))
ridge.caret = train(x, y,
method = 'glmnet',
trControl = train_control, tuneGrid = tune.grid)
### Plot the tuning object:
plot(ridge.caret, xTrans=log)
