{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test name          Statistic     p-value\n",
      "------------------ ----------------- -------\n",
      "D’Agostino-Pearson 2621.605094889189     0.0\n",
      "       Jarque-Bera 2781418.955449461     0.0\n",
      "    Test name          Statistic              p-value        \n",
      "------------------ ------------------ -----------------------\n",
      "D’Agostino-Pearson  611.7355784839505 1.4564880987184062e-133\n",
      "       Jarque-Bera 3478.3752328115315                     0.0\n",
      "lambda = 0.702711\n",
      "lambda = 0.691764\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# cd ~/Documents/NYC\\ Data\\ Science\\ Academy/HousingPrice_ML_Project/\n",
    "###############################################################################\n",
    "############################### READ IN DATA ##################################\n",
    "###############################################################################\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "train_id = df[\"Id\"]\n",
    "df2 = pd.read_csv(\"data/test.csv\")\n",
    "test_id = df2[\"Id\"]\n",
    "df2 = pd.concat([df2, pd.DataFrame(np.zeros(len(df2)), columns = ['SalePrice'])], axis = 1)\n",
    "#df = df.drop(\"Id\", axis = 1)\n",
    "df = df.merge(df2, on = df.columns.tolist(), how = \"outer\")\n",
    "df.set_index(\"Id\", inplace = True)\n",
    "del(df2)\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "# Columns with missing data\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "## MISSINGNESS IN COLUMNS\n",
    "df.isnull().sum(axis = 0).sort_values(ascending = False)\n",
    "# Percent of missingness in each column\n",
    "df.isnull().sum(axis = 0).sort_values(ascending = False)/df.shape[0]\n",
    "\n",
    "## MISSINGNESS IN ROWS\n",
    "df.isnull().sum(axis = 1).sort_values(ascending = False)\n",
    "# Percent of missingness in each row\n",
    "df.isnull().sum(axis = 1).sort_values(ascending = False)/df.shape[1]\n",
    "\n",
    "df.columns\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "############################ FILL IN MISSING DATA ##############################\n",
    "###############################################################################\n",
    "\n",
    "## MSZoning: Fill in with most common value\n",
    "df['MSZoning'].value_counts()\n",
    "sum(df['MSZoning'].isna())\n",
    "df['MSZoning'].fillna(\"RL\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "#################### Filling in LotFrontage with log(LotArea) #################\n",
    "#We can impute the missing data with the log-transform of lot area, correlation ~0.68\n",
    "df[['LotFrontage','LotArea']].corr()\n",
    "pd.concat([df['LotFrontage'], np.log(df['LotArea'])], axis = 1).corr()\n",
    "df['LotFrontage'] = np.log(df['LotArea'])\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "## Filling in \"NaN\" in Alley with \"None\"\n",
    "df['Alley'].value_counts()\n",
    "sum(df['Alley'].isna())\n",
    "df['Alley'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "## Filling in missing Utilities with AllPub (most common)\n",
    "df['Utilities'].value_counts()\n",
    "df['Utilities'].fillna(\"AllPub\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "## Filling in Exterior1st and Exterior2nd with most common values\n",
    "df['Exterior1st'].value_counts()\n",
    "sum(df['Exterior1st'].isna())\n",
    "df['Exterior1st'].fillna(\"VinylSd\", inplace = True)\n",
    "df['Exterior2nd'].value_counts()\n",
    "sum(df['Exterior2nd'].isna())\n",
    "df['Exterior2nd'].fillna(\"VinylSd\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# MasVnrType: NaN values are the same for type and area -- assume \"None\" and \"0\"\n",
    "df[df['MasVnrType'].isna()].index\n",
    "df[df['MasVnrArea'].isna()].index\n",
    "df['MasVnrType'].fillna(\"NA\", inplace = True)\n",
    "df['MasVnrArea'].fillna(0, inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# Basement\n",
    "# BsmtQual: None\n",
    "df['BsmtQual'].fillna(\"NA\", inplace = True)\n",
    "# BsmtCond: None\n",
    "df['BsmtCond'].fillna(\"NA\", inplace = True)\n",
    "# BsmtExposure: None\n",
    "df['BsmtExposure'].fillna(\"NA\", inplace = True)\n",
    "# BsmtFinType1: None\n",
    "df['BsmtFinType1'].fillna(\"NA\", inplace = True)\n",
    "# No basement\n",
    "df['BsmtFinSF1'].fillna(0, inplace = True)\n",
    "# BsmtFinType2: None\n",
    "df['BsmtFinType2'].fillna(\"NA\", inplace = True)\n",
    "# No basement\n",
    "df['BsmtFinSF2'].fillna(0, inplace = True)\n",
    "# No basement\n",
    "df['BsmtUnfSF'].fillna(0, inplace = True)\n",
    "# No basement\n",
    "df['TotalBsmtSF'].fillna(0, inplace = True)\n",
    "# No basement\n",
    "df['BsmtFullBath'].fillna(0, inplace = True)\n",
    "# No basement\n",
    "df['BsmtHalfBath'].fillna(0, inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# We decided to fill in the onemissing \"Electrical\" value with \"SBrkr\" since this is the most common one\n",
    "df['Electrical'].value_counts()\n",
    "df['Electrical'].fillna(\"SBrkr\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# No kitchen\n",
    "df['KitchenQual'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# Functional: fill mode\n",
    "df['Functional'].fillna(\"Typ\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# No fireplace\n",
    "df['FireplaceQu'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# No garage\n",
    "df['GarageArea'].value_counts()\n",
    "df['GarageType'].fillna(\"NA\", inplace = True)\n",
    "df['GarageYrBlt'].fillna(0, inplace = True)\n",
    "df['GarageFinish'].fillna(\"NA\", inplace = True)\n",
    "df['GarageCars'].fillna(0, inplace = True)\n",
    "df['GarageArea'].fillna(0, inplace = True)\n",
    "df['GarageQual'].fillna(\"NA\", inplace = True)\n",
    "df['GarageCond'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# No pool\n",
    "sum(df['PoolQC'].isna())\n",
    "df['PoolArea'].value_counts()\n",
    "df['PoolQC'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# No fence\n",
    "df['Fence'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# Fill in MiscFeature\n",
    "df['MiscFeature'].fillna(\"NA\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "# Fill in with most common SaleType\n",
    "df['SaleType'].fillna(\"WD\", inplace = True)\n",
    "df.columns[df.isnull().any(axis = 0)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "############################# DUMMIFY VARIABLES ###############################\n",
    "###############################################################################\n",
    "df_fe = df.copy()\n",
    "\n",
    "#Begin feature extraction\n",
    "#######################################################\n",
    "#Col ID\n",
    "#Remove Col Id\n",
    "#df_fe = df_fe.drop('Id', axis = 1)\n",
    "#######################################################\n",
    "#MSSubClass\n",
    "dummy_df = pd.get_dummies(df_fe['MSSubClass'], drop_first=True, prefix = 'MSSubClass')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('MSSubClass', axis = 1)\n",
    "#######################################################\n",
    "#MSZoning\n",
    "dummy_df = pd.get_dummies(df_fe['MSZoning'], drop_first=True, prefix = 'MSZoning')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('MSZoning', axis = 1)\n",
    "#######################################################\n",
    "#Lot Frontage\n",
    "df_fe = df_fe.drop('LotFrontage', axis = 1)\n",
    "#######################################################\n",
    "#Area\n",
    "#######################################################\n",
    "#Street\n",
    "#Remove Column\n",
    "dummy_df = pd.get_dummies(df_fe['Street'], drop_first=True, prefix = 'Street')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Street', axis = 1)\n",
    "#######################################################\n",
    "#Alley\n",
    "dummy_df = pd.get_dummies(df_fe['Alley'], drop_first=True, prefix = 'Alley')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Alley', axis = 1)\n",
    "#######################################################\n",
    "#LotShape\n",
    "dummy_df = pd.get_dummies(df_fe['LotShape'], drop_first=True, prefix = 'LotShape')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('LotShape', axis = 1)\n",
    "#######################################################\n",
    "#LandContour\n",
    "dummy_df = pd.get_dummies(df_fe['LandContour'], drop_first=True, prefix = 'LandContour')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('LandContour', axis = 1)\n",
    "#######################################################\n",
    "#Utilities\n",
    "dummy_df = pd.get_dummies(df_fe['Utilities'], drop_first=True, prefix = 'Utilities')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Utilities', axis = 1)\n",
    "#######################################################\n",
    "#LotConfig\n",
    "dummy_df = pd.get_dummies(df_fe['LotConfig'], drop_first=True, prefix = 'LotConfig')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('LotConfig', axis = 1)\n",
    "#######################################################\n",
    "#LandSlope\n",
    "dummy_df = pd.get_dummies(df_fe['LandSlope'], drop_first=True, prefix = 'LandSlope')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis = 1)\n",
    "df_fe = df_fe.drop('LandSlope', axis = 1)\n",
    "#######################################################\n",
    "#Neighborhood\n",
    "dummy_df = pd.get_dummies(df_fe['Neighborhood'], drop_first=True, prefix = 'Neighborhood')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Neighborhood', axis = 1) \n",
    "#######################################################\n",
    "#Condition1\n",
    "dummy_df = pd.get_dummies(df_fe['Condition1'], drop_first=True, prefix = 'Condition1')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Condition1', axis = 1)\n",
    "#######################################################\n",
    "#Condition2\n",
    "dummy_df = pd.get_dummies(df_fe['Condition2'], drop_first=True, prefix = 'Condition2')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Condition2', axis = 1)\n",
    "#######################################################\n",
    "#BldgType\n",
    "dummy_df = pd.get_dummies(df_fe['BldgType'], drop_first=True, prefix = 'BldgType')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('BldgType', axis = 1)\n",
    "#######################################################\n",
    "#HouseStyle\n",
    "dummy_df = pd.get_dummies(df_fe['HouseStyle'], drop_first = True, prefix = \"HouseStyle\")\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis = 1) \n",
    "df_fe = df_fe.drop('HouseStyle', axis = 1)\n",
    "#######################################################\n",
    "#OverallQual\n",
    "##Create interaction feature OverallQualCond = OverallQual*OverallCond\n",
    "df_fe['OverallQualCond'] = df_fe['OverallQual']*df_fe['OverallCond']\n",
    "#Remove Column\n",
    "df_fe = df_fe.drop('OverallQual', axis = 1)\n",
    "#######################################################\n",
    "#OverallCond\n",
    "##Remove Column \n",
    "df_fe = df_fe.drop('OverallCond', axis = 1)\n",
    "#######################################################\n",
    "#YearBuilt\n",
    "#Create interaction feature Age = YearSold-YearBuilt\n",
    "df_fe['Age'] = df_fe['YrSold']-df_fe['YearBuilt']\n",
    "#######################################################\n",
    "#YearRemodAdd\n",
    "#Create interaction feature Age = YearSold-YearBuilt\n",
    "#######################################################\n",
    "#RoofStyle\n",
    "#Combine classes - 'Flat','Gambrel','Mansard','Shed' into a single class \"Other\"\n",
    "dummy_df = pd.get_dummies(df_fe['RoofStyle'], drop_first=True, prefix = 'RoofStyle')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('RoofStyle', axis = 1)\n",
    "#######################################################\n",
    "#RoofMatl\n",
    "#Combine classes - 'Tar&Grv','WdShngl','WdShake','Roll','Membran','Metal','ClyTile' \n",
    "#into a single class \"NotShingle\"\n",
    "dummy_df = pd.get_dummies(df_fe['RoofMatl'], drop_first=True, prefix = 'RoofMatl')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('RoofMatl', axis = 1)\n",
    "#######################################################\n",
    "#Exterior1st\n",
    "dummy_df = pd.get_dummies(df_fe['Exterior1st'], drop_first=True, prefix = 'Exterior1st')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Exterior1st', axis = 1)\n",
    "#######################################################\n",
    "#Exterior2nd\n",
    "dummy_df = pd.get_dummies(df_fe['Exterior2nd'], drop_first=True, prefix = 'Exterior2nd')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Exterior2nd', axis = 1)\n",
    "#######################################################\n",
    "#MasVnrType\n",
    "dummy_df = pd.get_dummies(df_fe['MasVnrType'], drop_first=True, prefix = 'MasVnrType')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('MasVnrType', axis = 1)\n",
    "#######################################################\n",
    "#MasVnrArea\n",
    "#######################################################\n",
    "#ExterQual\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['ExterQual'] = df_fe['ExterQual'].map(ord_map)\n",
    "#######################################################\n",
    "#ExterCond\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['ExterCond'] = df_fe['ExterCond'].map(ord_map)\n",
    "\n",
    "df_fe['ExterScore'] = df_fe['ExterQual']*df_fe['ExterCond']\n",
    "df_fe = df_fe.drop(['ExterQual','ExterCond'], axis = 1)\n",
    "#######################################################\n",
    "#Foundation\n",
    "#Dummify\n",
    "dummy_df = pd.get_dummies(df_fe['Foundation'], drop_first=True, prefix = 'Foundation')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Foundation', axis = 1)\n",
    "#######################################################\n",
    "#BsmtQual\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['BsmtQual'] = df_fe['BsmtQual'].map(ord_map)\n",
    "#######################################################\n",
    "#BsmtCond\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['BsmtCond'] = df_fe['BsmtCond'].map(ord_map)\n",
    "#######################################################\n",
    "#BsmtExposure\n",
    "dummy_df = pd.get_dummies(df_fe['BsmtExposure'], drop_first=True, prefix = 'BsmtExposure')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('BsmtExposure', axis = 1)\n",
    "#######################################################\n",
    "#BsmtFinType1\n",
    "dummy_df = pd.get_dummies(df_fe['BsmtFinType1'], drop_first=True, prefix = 'BsmtFinType1')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('BsmtFinType1', axis = 1)\n",
    "#######################################################\n",
    "#BsmtFinSF1\n",
    "#######################################################\n",
    "#BsmtFinType2\n",
    "dummy_df = pd.get_dummies(df_fe['BsmtFinType2'], drop_first=True, prefix = 'BsmtFinType2')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('BsmtFinType2', axis = 1)    \n",
    "#######################################################\n",
    "#BsmtFinSF2\n",
    "#######################################################\n",
    "#BsmtUnfSF\n",
    "#######################################################\n",
    "#TotalBsmtSF\n",
    "#Remove Column Due to Multicolinearity w/1st Flr sqft\n",
    "df_fe = df_fe.drop(['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF'], axis = 1)\n",
    "#######################################################\n",
    "#Heating\n",
    "dummy_df = pd.get_dummies(df_fe['Heating'], drop_first=True, prefix = 'Heating')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Heating', axis = 1)\n",
    "#######################################################\n",
    "#HeatingQC\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['HeatingQC'] = df_fe['HeatingQC'].map(ord_map)\n",
    "#######################################################\n",
    "#CentralAir\n",
    "#Create Binary\n",
    "ls = ['Y']\n",
    "df_fe['CentralAir_Bin'] = [1 if x in ls else 0 for x in df_fe['CentralAir'] ]\n",
    "df_fe = df_fe.drop('CentralAir', axis = 1)\n",
    "#######################################################\n",
    "#Electrical\n",
    "dummy_df = pd.get_dummies(df_fe['Electrical'], drop_first=True, prefix = 'Electrical')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Electrical', axis = 1)   \n",
    "#######################################################\n",
    "#1stFlrSF\n",
    "df_fe = df_fe.drop('1stFlrSF', axis = 1) \n",
    "#2ndFlrSF\n",
    "df_fe = df_fe.drop('2ndFlrSF', axis = 1) \n",
    "#######################################################\n",
    "#LowQualFinSF\n",
    "#######################################################\n",
    "#GrLivArea\n",
    "df_fe['OverallScore'] = df_fe['GrLivArea']*df_fe['OverallQualCond']\n",
    "df_fe = df_fe.drop(['GrLivArea','OverallQualCond'], axis = 1)\n",
    "\n",
    "#######################################################\n",
    "#BsmtFullBath\n",
    "#######################################################\n",
    "#BsmtHalfBath\n",
    "#######################################################\n",
    "#FullBath\n",
    "#######################################################\n",
    "#HalfBath\n",
    "df_fe['TotalBath'] = (df_fe['FullBath'] + .5*df_fe['HalfBath'] + \n",
    "                        df_fe['BsmtFullBath'] + .5*df_fe['BsmtHalfBath'])\n",
    "#Remove Column\n",
    "df_fe = df_fe.drop(['FullBath','HalfBath','BsmtFullBath','BsmtHalfBath'], axis = 1)\n",
    "#######################################################\n",
    "#BedroomAbvGr\n",
    "#######################################################\n",
    "#KitchenAbvGr\n",
    "#######################################################\n",
    "#KitchenQual\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['KitchenQual'] = df_fe['KitchenQual'].map(ord_map)\n",
    "#######################################################\n",
    "#TotRmsAbvGrd\n",
    "#######################################################\n",
    "#Functional\n",
    "dummy_df = pd.get_dummies(df_fe['Functional'], drop_first=True, prefix = 'Functional')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Functional', axis = 1)  \n",
    "#######################################################\n",
    "#Fireplaces\n",
    "#######################################################\n",
    "#FireplaceQu\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "df_fe['FireplaceQu'] = df_fe['FireplaceQu'].map(ord_map)\n",
    "#######################################################\n",
    "#GarageType\n",
    "dummy_df = pd.get_dummies(df_fe['GarageType'], drop_first=True, prefix = 'GarageType')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('GarageType', axis = 1)\n",
    "#######################################################\n",
    "#GarageYrBlt\n",
    "df_fe['Gar_Age'] = df_fe['YrSold']-df_fe['GarageYrBlt']\n",
    "#Remove Column\n",
    "df_fe = df_fe.drop('GarageYrBlt', axis = 1)\n",
    "#######################################################\n",
    "#GarageFinish\n",
    "dummy_df = pd.get_dummies(df_fe['GarageFinish'], drop_first=True, prefix = 'GarageFinish')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('GarageFinish', axis = 1)   \n",
    "#######################################################\n",
    "#GarageCars\n",
    "#######################################################\n",
    "#GarageArea\n",
    "#######################################################\n",
    "#GarageQual\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['GarageQual'] = df_fe['GarageQual'].map(ord_map)\n",
    "#######################################################\n",
    "#GarageCond\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['GarageCond'] = df_fe['GarageCond'].map(ord_map)\n",
    "\n",
    "\n",
    "#Create interaction feature: GarageScore = GarageQual*GarageCond*GarageArea\n",
    "df_fe['GarageScore'] = df_fe['GarageQual']*df_fe['GarageCond']*df_fe['GarageArea']\n",
    "#Remove Columns\n",
    "df_fe = df_fe.drop(['GarageQual','GarageCond','GarageArea','GarageCars'], axis = 1)\n",
    "#######################################################\n",
    "#PavedDrive\n",
    "dummy_df = pd.get_dummies(df_fe['PavedDrive'], drop_first=True, prefix = 'PavedDrive')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('PavedDrive', axis = 1)\n",
    "#######################################################\n",
    "#WoodDeckSF\n",
    "#######################################################\n",
    "#OpenPorchSF\n",
    "#######################################################\n",
    "#EnclosedPorch\n",
    "#######################################################\n",
    "#3SsnPorch\n",
    "#######################################################\n",
    "#ScreenPorch\n",
    "#######################################################\n",
    "#PoolArea\n",
    "#All weekly correlated with price\n",
    "#df_fe = df_fe.drop(['EnclosedPorch','3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal'],axis = 1)\n",
    "#######################################################\n",
    "#PoolQC\n",
    "#Set Ordinal Mapping\n",
    "ord_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1,'NA':0}\n",
    "df_fe['PoolQC'] = df_fe['PoolQC'].map(ord_map)\n",
    "#######################################################   \n",
    "#Fence\n",
    "dummy_df = pd.get_dummies(df_fe['Fence'], drop_first=True, prefix = 'Fence')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('Fence', axis = 1)  \n",
    "#######################################################\n",
    "#MiscFeature\n",
    "dummy_df = pd.get_dummies(df_fe['MiscFeature'], drop_first=True, prefix = 'MiscFeature')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('MiscFeature', axis = 1) \n",
    "#######################################################\n",
    "#MiscVal\n",
    "#######################################################\n",
    "#MoSold\n",
    "#Dummify\n",
    "dummy_df = pd.get_dummies(df_fe['MoSold'], drop_first=True, prefix = 'MoSold')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('MoSold', axis = 1) \n",
    "#######################################################\n",
    "#YrSold\n",
    "#Dummify\n",
    "#dummy_df = pd.get_dummies(df_fe['YrSold'], drop_first=True, prefix = 'YrSold')\n",
    "#df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "#df_fe = df_fe.drop('YrSold', axis = 1) \n",
    "#######################################################\n",
    "#SaleType\n",
    "#Dummify\n",
    "dummy_df = pd.get_dummies(df_fe['SaleType'], drop_first=True, prefix = 'SaleType')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('SaleType', axis = 1) \n",
    "#######################################################\n",
    "#SaleCondition\n",
    "#Dummify\n",
    "dummy_df = pd.get_dummies(df_fe['SaleCondition'], drop_first=True, prefix = 'SaleCondition')\n",
    "df_fe = pd.concat([df_fe, dummy_df], axis=1)\n",
    "df_fe = df_fe.drop('SaleCondition', axis = 1) \n",
    "#######################################################\n",
    "#SalePrice\n",
    "\n",
    "del (dummy_df, ls, ord_map)\n",
    "\n",
    "df_fe.columns[df_fe.isnull().any(axis = 0)]\n",
    "\n",
    "###############################################################################\n",
    "########################### SPLIT TRAIN AND TEST ##############################\n",
    "###############################################################################\n",
    "\n",
    "train = df_fe.drop(index = test_id)\n",
    "train = pd.concat([train.drop('SalePrice', axis = 1), train['SalePrice']], axis = 1)\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "test = df_fe.drop(index = train_id).drop('SalePrice', axis = 1)\n",
    "test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "num_features = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1','BsmtFinSF2',\n",
    "                'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF','LowQualFinSF',\n",
    "                'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice']\n",
    "#num_features = train[num_features]\n",
    "#num_features.hist(figsize=(15,15))\n",
    "#train['LotFrontage']\n",
    "\n",
    "\n",
    "########################## OUTLIER IDENTIFICATION & REMOVAL ############################\n",
    "#Get Z score. If absolute score is greater than 3, then it is outlier and remove\n",
    "#z = np.abs(stats.zscore(num_features))\n",
    "#threshold = 3\n",
    "#train = train[(z < threshold).all(axis=1)]\n",
    "\n",
    "#train = train.drop(index = [313,335,934,313,335,249,706,129,1190,1328,197,523,1298,825,632,120,271,666,944,1230,1270,1275,1386])\n",
    "train = train.drop(index = [825,632,523,1298])\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "#sns.pairplot(num_features)\n",
    "#for column in num_features.columns:\n",
    "#    if column != \"SalePrice\":\n",
    "#        sns.jointplot(x = num_features[column], y = num_features['SalePrice'])\n",
    "\n",
    "\n",
    "########################## BOX-COX TRANSFORMATIONS ############################\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.jarque_bera.html\n",
    "#http://dataunderthehood.com/2018/01/15/box-cox-transformation-with-python/\n",
    "def normtesttab(x):\n",
    "    nm_value, nm_p = stats.normaltest(x)\n",
    "    jb_value, jb_p = stats.jarque_bera(x)\n",
    "    data_rows = [('D’Agostino-Pearson', nm_value, nm_p),\n",
    "                 ('Jarque-Bera', jb_value, jb_p)]\n",
    "    t = Table(rows=data_rows, names=('Test name', 'Statistic', 'p-value'), \n",
    "              meta={'name': 'normal test table'},\n",
    "          dtype=('S25', 'f8', 'f8'))\n",
    "    print(t)\n",
    "\n",
    "normtesttab(train['LotArea'])\n",
    "#normtesttab(train['GarageArea'])\n",
    "normtesttab(train['SalePrice'])\n",
    "\n",
    "# BOX COX TRAIN\n",
    "xt, maxlog, interval = stats.boxcox(train['GarageScore'] + abs(min(train['GarageScore']))+1, alpha=0.05)\n",
    "print(\"lambda = {:g}\".format(maxlog))\n",
    "# Power transform with 0.8\n",
    "train['GarageScore'] = (train['GarageScore'] + abs(min(train['GarageScore']))+1)**0.8\n",
    "\n",
    "# Log transform SalePrice\n",
    "train['SalePrice'] = np.log(train['SalePrice'])\n",
    "## To untransform sale price, np.exp(prediction price)\n",
    "\n",
    "#num_features = train[num_features]\n",
    "#num_features.hist(figsize=(15,15))\n",
    "\n",
    "# BOX COX TEST\n",
    "xt, maxlog, interval = stats.boxcox(test['GarageScore'] + abs(min(test['GarageScore']))+1, alpha=0.05)\n",
    "print(\"lambda = {:g}\".format(maxlog))\n",
    "# Power transform with 0.8\n",
    "test['GarageScore'] = (test['GarageScore'] + abs(min(test['GarageScore']))+1)**0.8\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "############################# STANDARDIZE DATA ################################\n",
    "###############################################################################\n",
    "to_scale = train.drop(columns = ['SalePrice'])\n",
    "colnames = to_scale.columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(to_scale)\n",
    "scaled_features = pd.DataFrame(scaler.transform(to_scale),\n",
    "             columns = to_scale.columns)\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(train[['SalePrice']])\n",
    "scaled_price = pd.DataFrame(scaler2.transform(train[['SalePrice']]),\n",
    "                            columns = ['SalePrice'])\n",
    "\n",
    "train = pd.concat([scaled_features, scaled_price], axis = 1)\n",
    "\n",
    "train.to_csv(\"data/train_clean_std_full.csv\", index = False)\n",
    "\n",
    "# Standardize test set\n",
    "test = pd.DataFrame(scaler.transform(test),\n",
    "             columns = test.columns)\n",
    "\n",
    "test.to_csv(\"data/test_clean_std_full.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
